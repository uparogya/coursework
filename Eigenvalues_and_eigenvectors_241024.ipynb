{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalues and eigenvectors\n",
    "\n",
    "Our matrix equation $A \\mathbf{x}= \\mathbf{b}$ represents a linear tranformation of vector spaces.  \n",
    "\n",
    "When $A$ is an $m \\times n$ matrix, $A$ maps vector $\\mathbf{x} \\in \\mathbb{R}^n$ to vector $\\mathbf{b} \\in \\mathbb{R}^m.$ \n",
    "If $A$ is a square matrix with $n$ rows and $n$ columns, then $A$ maps $\\mathbb{R}^n$ into $\\mathbb{R}^n.$ \n",
    "\n",
    "Are there are any nonzero vectors whose 'direction' does not change after matrix multiplication by $A?$ \n",
    "\n",
    "Algebraically, we consider vectors that are scalar multiples of themselves under matrix multiplication by $A$ represented by the matrix equation\n",
    "\n",
    "$$A\\mathbf{x}=\\lambda \\textbf{x}.$$\n",
    "\n",
    "\n",
    "Any $\\lambda$ and associated nonzero vector(s) $\\mathbf{x}$ that satisfy this equation are called *eigenvalues* and *eigenvectors* of $A.$ Note that eigenvectors are always associated with a particular $\\lambda,$ and eigenvectors are nonzero vectors by definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nullspace of $ A -\\lambda I $\n",
    "\n",
    "Moving $\\lambda \\mathbf{x}$ to the left side of the equation above gives $A\\mathbf{x}-\\lambda \\mathbf{x}  = \\mathbf{0}.$ \n",
    "\n",
    "Continuing by multiplying by the $ n \\times n$ identity matrix $I$ appropriately and factoring out the vector $\\mathbf{x}$ turns the definition for eigenvalues and eigenvectors into a nullspace problem for the matrix $A-\\lambda I$ as follows,  \n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "A\\mathbf{x}-\\lambda \\mathbf{x}  & = \\mathbf{0}, \\\\\n",
    "A \\mathbf{x} - \\lambda I \\mathbf{x} & = \\mathbf{0}, \\\\\n",
    "(A-\\lambda I)\\mathbf{x}  & = \\mathbf{0}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "Eigenvectors of $A$ are in the nullspace of the matrix $A-\\lambda I.$  \n",
    "\n",
    "If the determinant of $A-\\lambda I$ is zero, then this matrix is *singular*, (not invertible,) and we have a nontrivial nullspace (i.e. the nullspace is not just the zero vector.)  \n",
    "\n",
    "When the dimension of $\\text{Null}(A-\\lambda I)$ is $n,$ we can find $n$ independent eigenvectors of $A$ giving an *eigenbasis* for $\\mathbb{R}^n.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding eigenvalues and eigenvectors\n",
    "\n",
    "To find the eigenvalues of $A,$ we form the matrix $A-\\lambda I$ and consider the values $\\lambda$ that make $\\det(A-\\lambda I)=0.$\n",
    "\n",
    "Let\n",
    "$A=\\begin{bmatrix} \n",
    ".8 & .3 \\\\ \n",
    ".2 & .7 \\end{bmatrix}.\n",
    "$ \n",
    "\n",
    "\n",
    "Then $(A-\\lambda I)=\n",
    "\\begin{bmatrix} \n",
    ".8-\\lambda & .3 \\\\ \n",
    ".2 & .7-\\lambda \n",
    "\\end{bmatrix},$ \n",
    "\n",
    "with \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\det (A-\\lambda I) & = (.8-\\lambda) (.7-\\lambda) - (.3)(.2)\\\\\n",
    "& =  0.56 - 1.5\\lambda + \\lambda^2 - 0.06 \\\\\n",
    "& = \\lambda^2 - 1.5 \\lambda + 0.5 \\\\\n",
    "& = ( \\lambda - 1 ) (\\lambda - 0.5).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "We call $\\det (A-\\lambda I) = 0 $ the *characteristic equation*. Solving for the $\\lambda$'s which make  $\\displaystyle{\\det (A-\\lambda I) = 0}$ is the same as finding the roots of the characteristic equation.  \n",
    "\n",
    "Here we have two distinct eigenvalues $\\lambda_1 = 1$ and $\\lambda_2 = \\frac{1}{2}.$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1\n",
    "\n",
    "Finding eigenvectors associated with eigenvalues $\\lambda_1 = 1$ and $\\lambda_2 = \\frac{1}{2}$, is done by finding vectors in the nullspaces of $(A-\\lambda_1 I)$ and $(A-\\lambda_2 I)$ respectively.\n",
    "\n",
    "For $A$ listed in our example above, find eigenvectors associated with eigenvalues $\\lambda_1 = 1$ and $\\lambda_2 = \\frac{1}{2}.$ Do this by hand and list your eigenvectors in the answer box below.\n",
    "\n",
    "\n",
    ">\n",
    ">Please write up your answer here.\n",
    ">\n",
    "> [.8-1  .3]\n",
    "> [.2  .7-1]\n",
    ">\n",
    "> [-.2  .3]\n",
    "> [.2  -.3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Code\n",
    "\n",
    "The following code cells demo the $\\texttt{np.linalg.eig()}$ command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix A is\n",
      " [[0.8 0.3]\n",
      " [0.2 0.7]] \n",
      "\n",
      "The eigenvalues of A are [1.  0.5] \n",
      "\n",
      "The diagonal eigenvalue matrix Lambda is\n",
      " [[1.  0. ]\n",
      " [0.  0.5]] \n",
      "\n",
      "The eigenvector matrix V is\n",
      " [[ 0.83205029 -0.70710678]\n",
      " [ 0.5547002   0.70710678]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input matrix A\n",
    "A = np.array([[.8, .3],\n",
    "              [.2, .7]])\n",
    "\n",
    "print(\"The matrix A is\\n\", A, \"\\n\")\n",
    "\n",
    "# the linalg.eig() command will return a vector d containing eigenvalues, and a matrix V with associated\n",
    "# unit length eigenvectors of A as cols of V\n",
    "\n",
    "d, V = np.linalg.eig(A)\n",
    "\n",
    "print(\"The eigenvalues of A are\", d, \"\\n\")\n",
    "\n",
    "# Make the diagonal matrix D with eigenvalues of A on the diagonal.\n",
    "D = np.diag(d)\n",
    "print(\"The diagonal eigenvalue matrix Lambda is\\n\", D, \"\\n\")\n",
    "print(\"The eigenvector matrix V is\\n\", V, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector x is \n",
      " [[1.5]\n",
      " [1. ]] \n",
      "\n",
      "The length of x is 1.8027756377319946 \n",
      "\n",
      "x1 is a unit vector in the direction of x \n",
      " [[0.83205029]\n",
      " [0.5547002 ]] \n",
      "\n",
      "The matrix product Ax is the vector\n",
      " [[1.5]\n",
      " [1. ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note that eigenvectors are normalized so that they are unit vectors, (length = 1).\n",
    "# take x as an eigenvector we found by hand, and divide by its length (done for you.)\n",
    "\n",
    "x = np.array([[3/2],\n",
    "              [1]])\n",
    "\n",
    "print(\"The vector x is \\n\", x,  \"\\n\")\n",
    "print(\"The length of x is\", np.linalg.norm(x), \"\\n\")\n",
    "\n",
    "#x1 is a unit vector in the same direction as x\n",
    "x1 = x/(np.linalg.norm(x))\n",
    "print(\"x1 is a unit vector in the direction of x \\n\", \n",
    "      x1, \"\\n\")\n",
    "\n",
    "# What does A@x give us? Is this what we expect based on the theory?\n",
    "print(\"The matrix product Ax is the vector\\n\", A@x, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.80277564]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check length calculation using (Pythagoras, dot product) of the eigenvector you found by hand. \n",
    "# Values may vary based on your x.\n",
    "np.sqrt( x.T@x )#[0]#[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "#### Question 2\n",
    "\n",
    "How do the eigenvalues and associated eigenvectors compare to what you found by hand?  Comment briefly.\n",
    "\n",
    "\n",
    ">\n",
    ">Please write up your answer here.\n",
    "> The vector that we get by computer when divided by np.linalg.norm(the_vector) gives what we get by doing it by doing it by hand.\n",
    "> Computer gives the unit vector which is just the unstretched version of what is calculated by hand.\n",
    ">They are on the same line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Diagonalization\n",
    "\n",
    "Suppose that the $n \\times n$ matrix $A,$ has $n$ linearly independent eigenvectors $\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n,$ and let $V$ be a matrix whose columns are $n$ linearly independent eigenvectors of $A$.   \n",
    "\n",
    "Then, $V^{-1}AV$ will be a diagonal matrix, $D,$ with diagonal entries consisting of the eigenvalues of $A.$ \n",
    "\n",
    "In this case, we say that $A$ is *diagonalizable*, or $A$ is *diagonalized* by $V.$\n",
    "\n",
    "This also implies that $A=VDV^{-1},$ which we can use to compute $k^{\\text{th}}$ powers of $A.$ \n",
    "\n",
    "For large matrices it is much more efficient to compute powers of the diagonal matrix $D$ followed by two matrix products, than it would be to compute $A^k$ directly using $(k-1)$ matrix products.\n",
    "\n",
    "First note that for $D=\\begin{bmatrix} \\lambda_1 & & \\\\ & \\ddots & \\\\ && \\lambda_n \\end{bmatrix}, \\quad D^k=\\begin{bmatrix} \\lambda_1^k & & \\\\ & \\ddots & \\\\ && \\lambda_n^k \\end{bmatrix}. \\quad \\quad$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 3\n",
    "\n",
    "Why does $D^k$ have powers of the eigenvalues along the diagonal?  Explain in terms of your understanding of matrix products.\n",
    "\n",
    ">\n",
    "> The rest of the values except the ones in the diagonal are 0s. Therefore when we increase the power, we are just finding the dot product of matrix with the previous power. Therefore the power of eigenvalues along the diagonal increases in the exponent of k.\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Matrix powers\n",
    "\n",
    "Second, note that squaring $A$ using its diagonalization, $\\left( V D V^{-1} \\right),$ \n",
    "\n",
    "gives\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "A^2 & = \\left( V D V^{-1} \\right) \\left( V D V^{-1} \\right ) \\\\\n",
    "& = V D \\left( V^{-1} V \\right) D V^{-1} \\\\\n",
    "& = V D \\left( I_n \\right) D V^{-1} \\\\\n",
    "& = V D^2 V^{-1}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "In general, we have $A^k = VD^kV^{-1}.$\n",
    "\n",
    "Answer the following questions first. Then compute powers of $A$ using the code given, and compare with what you thought was going to happen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 4\n",
    "\n",
    "What is the limit of $A^k$ as $k\\rightarrow \\infty?$ How can we determine this limit from the diagonalization of $A?$ Explain based on the discussion above, and then check using the code below. What do you find?\n",
    "\n",
    ">\n",
    "> As k goes to infinity:\n",
    ">\n",
    "> A = V D V^(-1)\n",
    "\n",
    "> A^2 = V D^2 V^(-1)\n",
    "\n",
    "> A^3 = V D^3 V^(-1)\n",
    "\n",
    "> ...\n",
    ">\n",
    "\n",
    "> When we change the k below to larger and larger, the output gets smaller. The 1 stays intact showing the start of the diagonal matrix. Thus when k gets to infinity, the limit of A^k goes to 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6 0.6]\n",
      " [0.4 0.4]] \n",
      "\n",
      "[[1.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 7.88860905e-31]] \n",
      "\n",
      "[[0.6 0.6]\n",
      " [0.4 0.4]]\n"
     ]
    }
   ],
   "source": [
    "# For a 2x2 matrix powers are not that bad, but for large nxn matrices we would want to do something different\n",
    "# Compare computing A^2 with using our diagonalization from above.\n",
    "\n",
    "# Adjust k to find various powers of A^k.  What matrix does A^k approach for large k?\n",
    "k = 100\n",
    "print(np.linalg.matrix_power(A, k), \"\\n\")\n",
    "\n",
    "# Diagonalization\n",
    "print(np.linalg.matrix_power(D, k), \"\\n\")\n",
    "\n",
    "print(V@(np.linalg.matrix_power(D, k))@np.linalg.inv(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.6],\n",
       "       [0.2, 0.4]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another Markov example\n",
    "A = np.array([[.8, .6],\n",
    "              [.2, .4]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1\n",
      "[[0.8 0.6]\n",
      " [0.2 0.4]]\n",
      "\n",
      "K = 1000\n",
      "[[0.75 0.75]\n",
      " [0.25 0.25]]\n"
     ]
    }
   ],
   "source": [
    "# Check for different powers k.\n",
    "k = 1\n",
    "print(\"K = 1\")\n",
    "print(np.linalg.matrix_power(A, k))\n",
    "\n",
    "print(\"\\nK = 1000\")\n",
    "k = 1000\n",
    "print(np.linalg.matrix_power(A, k))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
